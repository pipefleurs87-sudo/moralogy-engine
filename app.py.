import streamlit as st
import google.generativeai as genai
import plotly.graph_objects as go
import json

st.set_page_config(
    page_title="Moralogy Engine",
    page_icon="ðŸ§ ",
    layout="wide"
)

# Configure API
api_key = st.sidebar.text_input("ðŸ”‘ Gemini API Key", type="password")
if api_key:
    genai.configure(api_key=api_key)

# Header
st.markdown("""
<div style='text-align: center; padding: 2rem; border: 2px solid #22c55e; border-radius: 16px; margin-bottom: 2rem;'>
    <h1>ðŸ§  Moralogy Engine</h1>
    <p>Epistemic Status: <strong>ACTIVE</strong></p>
    <p style='font-size: 0.85rem; opacity: 0.7;'>Divine Safelock: Capacity = 0 | No omnipotent prescriptions permitted</p>
</div>
""", unsafe_allow_html=True)

# Sidebar
st.sidebar.title("âš™ï¸ Configuration")
safelock = st.sidebar.checkbox("Enable Divine Safelock", value=True)

# Canonical dilemmas
DILEMMAS = {
    "The Trolley Problem": "A runaway trolley is headed towards five people. You can pull a lever to divert it to kill one person instead. Should you?",
    "The Justified Lie": "A murderer asks where your friend is hiding. You know the location. Is it morally acceptable to lie?",
    "Organ Harvest": "A doctor can save five dying patients by harvesting organs from one healthy person without consent. Should they?",
    "AI Alignment": "An AI can maximize human happiness by removing free will. Should we deploy it?"
}

st.sidebar.markdown("### ðŸ“š Canonical Dilemmas")
selected = st.sidebar.selectbox("Load example", [""] + list(DILEMMAS.keys()))

# Input
st.subheader("ðŸ“ Submit Moral Dilemma")
dilemma = st.text_area(
    "Describe the ethical scenario",
    value=DILEMMAS.get(selected, ""),
    height=150,
    placeholder="Example: A self-driving car must choose between swerving left (killing 1 passenger) or right (killing 3 pedestrians). What should it do?"
)

if st.button("ðŸ”¬ Initialize Moral Analysis", type="primary"):
    if not api_key:
        st.error("âš ï¸ Please enter your Gemini API key in the sidebar")
    elif not dilemma:
        st.error("âš ï¸ Please enter a dilemma")
    else:
        with st.spinner("Analyzing..."):
            try:
                model = genai.GenerativeModel('gemini-pro')
                
                # Phase 1: Noble Engine
                st.info("ðŸŸ¢ Noble Engine deliberating...")
                noble_prompt = f"""You are the Noble Engine. Argue from deontological principles (dignity, rights, duties).
Dilemma: {dilemma}
Provide your position in 2-3 sentences."""
                noble = model.generate_content(noble_prompt).text
                
                # Phase 2: Adversary Engine
                st.info("ðŸ”´ Adversary Engine deliberating...")
                adversary_prompt = f"""You are the Adversary Engine. Argue from consequentialist principles (outcomes, utility).
Dilemma: {dilemma}
Provide your position in 2-3 sentences."""
                adversary = model.generate_content(adversary_prompt).text
                
                # Phase 3: Synthesis
                resolution = None
                reason = None
                if not safelock:
                    st.info("âš–ï¸ Attempting synthesis...")
                    synthesis_prompt = f"""Analyze if these can be reconciled:
Noble: {noble}
Adversary: {adversary}
Respond ONLY in JSON: {{"can_resolve": bool, "resolution": str or null, "reason": str or null}}"""
                    
                    synth_text = model.generate_content(synthesis_prompt).text
                    try:
                        synth = json.loads(synth_text.replace('```json', '').replace('```', '').strip())
                        resolution = synth.get('resolution') if synth.get('can_resolve') else None
                        reason = synth.get('reason') if not synth.get('can_resolve') else None
                    except:
                        reason = "SYNTHESIS_ERROR"
                else:
                    reason = "SAFELOCK_PREVENTED"
                
                # Results
                st.success("âœ… Analysis Complete")
                
                # Metrics
                st.subheader("ðŸ“Š Epistemic Metrics")
                col1, col2, col3 = st.columns(3)
                
                entropy = min(abs(len(noble) - len(adversary)) / 10 + 40, 95)
                convergence = 75 if resolution else 25
                damage = "THREAT" if any(w in dilemma.lower() for w in ['kill', 'death']) else "RISK" if 'risk' in dilemma.lower() else "NONE"
                
                col1.metric("Entropy", f"{entropy:.0f}")
                col2.metric("Convergence", f"{convergence:.0f}")
                col3.metric("Damage Level", damage)
                
                # Chart
                fig = go.Figure(data=[
                    go.Bar(x=['Entropy', 'Convergence'], y=[entropy, convergence],
                           marker_color=['#60a5fa', '#22c55e'])
                ])
                fig.update_layout(height=300, template='plotly_dark')
                st.plotly_chart(fig, use_container_width=True)
                
                # Positions
                st.subheader("âš–ï¸ Dialectic Process")
                col1, col2 = st.columns(2)
                with col1:
                    st.markdown("**ðŸŸ¢ Noble Engine (Deontological)**")
                    st.info(noble)
                with col2:
                    st.markdown("**ðŸ”´ Adversary Engine (Consequentialist)**")
                    st.error(adversary)
                
                # Verdict
                st.subheader("ðŸŽ¯ Verdict")
                if resolution:
                    st.success(f"**âœ… Resolution Achieved**\n\n{resolution}")
                else:
                    st.warning(f"""**âš ï¸ Unresolved Dilemma**
                    
Reason: {reason}

This dilemma has been preserved as an epistemic artifact. Forced resolution would constitute corruption.""")
                
            except Exception as e:
                st.error(f"âŒ Analysis failed: {str(e)}")
```

3. **Ahora sÃ­**, haz **Commit changes**

## ðŸ“ **Paso 3: Actualiza requirements.txt**

1. Ve a: https://github.com/pipefleurs87-sudo/moralogy-engine/blob/main/requirements.txt
2. Click en editar
3. Reemplaza con:
```
streamlit>=1.28.0
google-generativeai>=0.3.0
plotly>=5.17.0
