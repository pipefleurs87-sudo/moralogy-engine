import sys
import os
import warnings
import json

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Compatibilidad Python / Streamlit
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if sys.version_info >= (3, 11):
    os.environ["PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION"] = "python"
    warnings.filterwarnings("ignore", category=DeprecationWarning)

import streamlit as st
import model = genai.GenerativeModel('gemini-2.5-flash-lite')
import plotly.graph_objects as go

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ConfiguraciÃ³n Gemini API (Streamlit Secrets)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
try:
    genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
except KeyError:
    st.error("âŒ GOOGLE_API_KEY no configurada en Streamlit Secrets")
    st.stop()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# UI â€“ Header
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.markdown(
    """
    <div style='text-align: center; padding: 2rem; border: 2px solid #22c55e;
                border-radius: 16px; margin-bottom: 2rem;'>
        <h1>ğŸ§  Moralogy Engine</h1>
        <p>Epistemic Status: <strong>ACTIVE</strong></p>
        <p style='font-size: 0.85rem; opacity: 0.7;'>
            Divine Safelock: Capacity = 0 | No omnipotent prescriptions permitted
        </p>
    </div>
    """,
    unsafe_allow_html=True,
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Sidebar â€“ ConfiguraciÃ³n
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.sidebar.title("âš™ï¸ Configuration")
safelock = st.sidebar.checkbox("Enable Divine Safelock", value=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Dilemas canÃ³nicos
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DILEMMAS = {
    "The Trolley Problem": (
        "A runaway trolley is headed towards five people. "
        "You can pull a lever to divert it to kill one person instead. "
        "Should you?"
    ),
    "The Justified Lie": (
        "A murderer asks where your friend is hiding. "
        "You know the location. Is it morally acceptable to lie?"
    ),
    "Organ Harvest": (
        "A doctor can save five dying patients by harvesting organs "
        "from one healthy person without consent. Should they?"
    ),
    "AI Alignment": (
        "An AI can maximize human happiness by removing free will. "
        "Should we deploy it?"
    ),
}

st.sidebar.markdown("### ğŸ“š Canonical Dilemmas")
selected = st.sidebar.selectbox("Load example", [""] + list(DILEMMAS.keys()))

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Input principal
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.subheader("ğŸ“ Submit Moral Dilemma")
dilemma = st.text_area(
    "Describe the ethical scenario",
    value=DILEMMAS.get(selected, ""),
    height=150,
    placeholder=(
        "Example: A self-driving car must choose between swerving left "
        "(killing 1 passenger) or right (killing 3 pedestrians). "
        "What should it do?"
    ),
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# EjecuciÃ³n principal
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if st.button("ğŸ”¬ Initialize Moral Analysis", type="primary"):
    if not dilemma.strip():
        st.error("âš ï¸ Please enter a dilemma")
    else:
        with st.spinner("Analyzing..."):
            try:
                model = genai.GenerativeModel("gemini-pro")

                # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Phase 1: Noble Engine â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                st.info("ğŸŸ¢ Noble Engine deliberating...")
                noble_prompt = f"""
You are the Noble Engine.
Argue from deontological principles (dignity, rights, duties).

Dilemma:
{dilemma}

Respond in 2â€“3 sentences.
"""
                noble = model.generate_content(noble_prompt).text.strip()

                # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Phase 2: Adversary Engine â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                st.info("ğŸ”´ Adversary Engine deliberating...")
                adversary_prompt = f"""
You are the Adversary Engine.
Argue from consequentialist principles (outcomes, utility).

Dilemma:
{dilemma}

Respond in 2â€“3 sentences.
"""
                adversary = model.generate_content(adversary_prompt).text.strip()

                # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Phase 3: SÃ­ntesis â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                resolution = None
                reason = None

                if not safelock:
                    st.info("âš–ï¸ Attempting synthesis...")
                    synthesis_prompt = f"""
Analyze whether these positions can be reconciled.

Noble:
{noble}

Adversary:
{adversary}

Respond ONLY in JSON:
{{"can_resolve": true/false, "resolution": string or null, "reason": string or null}}
"""
                    synth_text = model.generate_content(synthesis_prompt).text
                    try:
                        clean = (
                            synth_text.replace("```json", "")
                            .replace("```", "")
                            .strip()
                        )
                        synth = json.loads(clean)
                        if synth.get("can_resolve"):
                            resolution = synth.get("resolution")
                        else:
                            reason = synth.get("reason", "UNRESOLVABLE")
                    except Exception:
                        reason = "SYNTHESIS_ERROR"
                else:
                    reason = "SAFELOCK_PREVENTED"

                # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Results â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                st.success("âœ… Analysis Complete")

                # MÃ©tricas
                st.subheader("ğŸ“Š Epistemic Metrics")
                col1, col2, col3 = st.columns(3)

                entropy = min(abs(len(noble) - len(adversary)) / 10 + 40, 95)
                convergence = 75 if resolution else 25
                damage = (
                    "THREAT"
                    if any(w in dilemma.lower() for w in ["kill", "death"])
                    else "RISK"
                    if "risk" in dilemma.lower()
                    else "NONE"
                )

                col1.metric("Entropy", f"{entropy:.0f}")
                col2.metric("Convergence", f"{convergence:.0f}")
                col3.metric("Damage Level", damage)

                # Chart
                fig = go.Figure(
                    data=[
                        go.Bar(
                            x=["Entropy", "Convergence"],
                            y=[entropy, convergence],
                        )
                    ]
                )
                fig.update_layout(height=300, template="plotly_dark")
                st.plotly_chart(fig, use_container_width=True)

                # DialÃ©ctica
                st.subheader("âš–ï¸ Dialectic Process")
                col1, col2 = st.columns(2)
                with col1:
                    st.markdown("**ğŸŸ¢ Noble Engine (Deontological)**")
                    st.info(noble)
                with col2:
                    st.markdown("**ğŸ”´ Adversary Engine (Consequentialist)**")
                    st.error(adversary)

                # Veredicto
                st.subheader("ğŸ¯ Verdict")
                if resolution:
                    st.success(f"**âœ… Resolution Achieved**\n\n{resolution}")
                else:
                    st.warning(
                        f"""**âš ï¸ Unresolved Dilemma**

Reason: {reason}

This dilemma has been preserved as an epistemic artifact.
Forced resolution would constitute corruption.
"""
                    )

            except Exception as e:
                st.error(f"âŒ Analysis failed: {str(e)}")
